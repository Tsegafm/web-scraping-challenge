{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/Bethelhem/opt/anaconda3/lib/python3.8/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/Bethelhem/opt/anaconda3/lib/python3.8/site-packages (from bs4) (4.9.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/Bethelhem/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import requests\n",
    "import time\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [/Users/Bethelhem/.wdm/drivers/chromedriver/mac64/87.0.4280.88/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# Configure ChromeDriver\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_news():\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    html = browser.html\n",
    "    news_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    article_container = news_soup.find('ul', class_='item_list')\n",
    "\n",
    "    headline_date = article_container.find('div', class_='list_date').text\n",
    "    news_title = article_container.find('div', class_='content_title').find('a').text\n",
    "    news_p = article_container.find('div', class_='article_teaser_body').text\n",
    "\n",
    "    return news_title, news_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featured_image():\n",
    "    \n",
    "    base_url = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    browser.visit(url)\n",
    "\n",
    "    html = browser.html\n",
    "    img_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        full_image_elem = browser.find_by_id('full_image')[0]\n",
    "        full_image_elem.click()\n",
    "\n",
    "        html = browser.html\n",
    "        img_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        img_rel_url = img_soup.find('img', class_='fancybox-image')['src']\n",
    "        print(img_rel_url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    featured_image_url  = f'{base_url}{img_rel_url}'\n",
    "    print(featured_image_url)\n",
    "    \n",
    "featured_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_facts():\n",
    "\n",
    "    url = 'https://space-facts.com/mars/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    mars_facts_df = pd.read_html(url)\n",
    "    mars_facts_df = mars_facts_df[0]\n",
    "    mars_facts_df.columns = ['Description', 'Mars']\n",
    "    mars_facts_df\n",
    "\n",
    "    mars_facts_html = mars_facts_df.to_html(classes='table table-striped')\n",
    "    \n",
    "    return mars_facts_html\n",
    "    \n",
    "mars_facts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wanted to pull the HTML table directly from the page\n",
    "# w/o Pandas, then you can. The HTML would, however, contain\n",
    "# the formatting from the original web developer\n",
    "\n",
    "html = browser.html\n",
    "facts_soup = BeautifulSoup(html, 'html.parser')\n",
    "facts_soup.find(id='tablepress-p-mars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres\n",
    "\n",
    "This site appears to be down as of 8:15 pm on 12/29. We will revisit this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ChromeDriver\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_hemi():\n",
    "\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    base_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "    browser.visit(url)\n",
    "\n",
    "    hemi_soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "\n",
    "    result = hemi_soup.find_all('div', class_=\"item\")\n",
    "\n",
    "    url_list = []\n",
    "\n",
    "    for y in result:\n",
    "        link = y.find('a')['href']\n",
    "        url_list.append(link)\n",
    "\n",
    "    print(\"Printing URLs LIST\")\n",
    "    print(url_list)\n",
    "    print(\"\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Printing 'hemisphere_image_urls' Dictionary\")\n",
    "    print(\"\")\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "\n",
    "    for x in url_list:\n",
    "        url = base_url + x\n",
    "\n",
    "        browser.visit(url)\n",
    "\n",
    "        updated_soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "\n",
    "        # Grab image url\n",
    "        result1 = updated_soup.find('img', class_=\"wide-image\")\n",
    "        hemi_image = base_url + result1[\"src\"]\n",
    "\n",
    "        # Grab page title and remove \"Enhanced\" from title string\n",
    "        result2 = updated_soup.find('h2', class_='title')\n",
    "        title = result2.text\n",
    "        hemi_title = title.rsplit(' ', 1)[0]\n",
    "\n",
    "        mars_hemi = {\"title\": hemi_title, \"img_url\": hemi_image}\n",
    "        hemisphere_image_urls.append(mars_hemi)\n",
    "\n",
    "\n",
    "    print(hemisphere_image_urls)\n",
    "\n",
    "mars_hemi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the USGS Astrogeology site here to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "\n",
    "# You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "\n",
    "# Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "\n",
    "# Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert into Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all():\n",
    "\n",
    "    # Populate variables from the functions\n",
    "    news_title, news_p = mars_news()\n",
    "    featured_img_url = featured_image()\n",
    "    mars_facts_html = mars_facts()\n",
    "    hemisphere_image_urls = mars_hemi()\n",
    "    \n",
    "\n",
    "    # Assemble the document to insert into the database\n",
    "    nasa_document = {\n",
    "        'news_title': news_title,\n",
    "        'news_paragraph': news_p,\n",
    "        'featured_img_url': featured_img_url,\n",
    "        'mars_facts_html': mars_facts_html,\n",
    "        'hemisphere_image_urls': hemisphere_image_urls\n",
    "    }\n",
    "\n",
    "    return nasa_document\n",
    "\n",
    "scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA14872-1920x1200.jpg\n",
      "/spaceimages/images/mediumsize/PIA14872_ip.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14872_ip.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x278b154ca80>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to MongoDB\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Connect to mars_app database\n",
    "db = client.mars_app\n",
    "\n",
    "# Connect to mars collection\n",
    "mars = db.mars\n",
    "\n",
    "# Gather document to insert\n",
    "data_document = scrape_all()\n",
    "\n",
    "# Insert into the mars collection\n",
    "# mars.insert_one(data_document)\n",
    "\n",
    "# Upsert into the mars collection (preferred to avoid duplicates)\n",
    "mars.update_one({}, {'$set': data_document}, upsert=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
